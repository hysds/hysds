import ssl
broker_use_ssl = {
    'ca_certs': "{{ CA_BUNDLE_CERT }}",
    'cert_reqs': ssl.CERT_NONE,
    'ciphers': "{{ CIPHERS }}"
}

broker_url = "amqps://{{ MOZART_RABBIT_USER }}:{{ MOZART_RABBIT_PASSWORD }}@{{ MOZART_RABBIT_PVT_IP }}:5671/"
result_backend = "rediss://:{{ MOZART_REDIS_PASSWORD }}@{{ MOZART_REDIS_PVT_IP }}/?ssl_cert_reqs=none"

task_serializer = "msgpack"
result_serializer = "msgpack"
accept_content = ["msgpack", "json"]

task_acks_late = True
result_expires = 86400
worker_prefetch_multiplier = 1

event_serializer = "msgpack"
worker_send_task_events = True
task_send_sent_event = True
task_track_started = True

task_queue_max_priority = 10

task_reject_on_worker_lost = True

broker_heartbeat = 60
broker_heartbeat_checkrate = 2

broker_pool_limit = None
broker_transport_options = { "confirm_publish": True,  "read_timeout": 60, "write_timeout": 60}
broker_connection_timeout = 60

redis_socket_keepalive = True
redis_backend_health_check_interval = 30

imports = [
    "hysds.task_worker",
    "hysds.job_worker",
    "hysds.orchestrator",
]

CELERY_SEND_TASK_ERROR_EMAILS = False
ADMINS = (
    ('{{ ADMIN_NAME }}', '{{ ADMIN_EMAIL }}'),
)
SERVER_EMAIL = '{{ HOST_STRING }}'

HYSDS_HANDLE_SIGNALS = False
HYSDS_JOB_STATUS_EXPIRES = 86400

BACKOFF_MAX_VALUE = 64
BACKOFF_MAX_TRIES = 10

# Job lock settings for distributed locking
JOB_LOCK_EXPIRE_TIME = 600  # Lock expiration time in seconds (10 minutes)
JOB_LOCK_HEARTBEAT_INTERVAL = 120  # Lock renewal interval in seconds (5 minutes)
JOB_LOCK_STALE_CHECK_TIMEOUT = 60  # Max time to retry checking task state (60 seconds)
JOB_LOCK_NEW_GRACE_PERIOD = 120  # Grace period for new locks in seconds (2 minutes)
JOB_LOCK_REDELIVERY_BUFFER_TIME = 10  # Buffer time in seconds for redelivery wait
JOB_LOCK_MAX_EXTENSIONS = 1080  # Max number of lock extensions (1080 = 1 day with 2-min heartbeat)
# JOB_LOCK_REDELIVERY_WAIT_MAX = None  # Optional: Max time to wait for lock renewal on redelivery
                                       # If not set, waits for full heartbeat interval + buffer
                                       # WARNING: Setting this < JOB_LOCK_HEARTBEAT_INTERVAL may break active locks!

PUBLISH_WAIT_BACKOFF_MAX_TIME = 300

HARD_TIME_LIMIT_GAP = 300

PYMONITOREDRUNNER_CFG = {
    "rabbitmq": {
        "hostname": "{{ MOZART_RABBIT_PVT_IP }}",
        "port": 5671,
        "queue": "stdouterr"
    },

    "StreamObserverFileWriter": {
        "stdout_filepath": "_stdout.txt",
        "stderr_filepath": "_stderr.txt"
    },

    "StreamObserverMessenger": {
        "send_interval": 1
    }
}

MOZART_URL = "https://{{ MOZART_PVT_IP }}/mozart/"
MOZART_REST_URL = "https://{{ MOZART_PVT_IP }}:8888/api/v0.1"

JOBS_ES_ENGINE = "{{ MOZART_ES_ENGINE or 'elasticsearch' }}"
JOBS_AWS_ES = {{ MOZART_AWS_ES or False }}
{%- if MOZART_ES_PVT_IP is iterable and MOZART_ES_PVT_IP is not string %}
JOBS_ES_URL = [
    {%- for url in MOZART_ES_PVT_IP %}
        {%- if url.startswith('https://') %}
    "{{ url }}",
        {%- else %}
    "{{ 'https://'~url if MOZART_AWS_ES == true or 'es.amazonaws.com' in url else 'https://'~url~':9200' }}",
        {%- endif %}
    {%- endfor %}
]
{%- else %}
    {%- if MOZART_ES_PVT_IP.startswith('https://') %}
JOBS_ES_URL = "{{ MOZART_ES_PVT_IP }}"
    {%- else %}
JOBS_ES_URL = "{{ 'https://'~MOZART_ES_PVT_IP if MOZART_AWS_ES == true or 'es.amazonaws.com' in MOZART_ES_PVT_IP else 'https://'~MOZART_ES_PVT_IP~':9200' }}"
    {%- endif %}
{%- endif %}

JOBS_PROCESSED_QUEUE = "jobs_processed"
USER_RULES_JOB_QUEUE = "user_rules_job"
ON_DEMAND_JOB_QUEUE = "on_demand_job"
USER_RULES_JOB_INDEX = "user_rules-mozart"
STATUS_ALIAS = "job_status"

TOSCA_URL = "https://{{ GRQ_PVT_IP }}/search/"
GRQ_URL = "https://{{ GRQ_PVT_IP }}:{{ GRQ_PORT }}"
GRQ_REST_URL = "https://{{ GRQ_PVT_IP }}:{{ GRQ_PORT }}/api/v0.1"
GRQ_UPDATE_URL = "https://{{ GRQ_PVT_IP }}:{{ GRQ_PORT }}/api/v0.1/grq/dataset/index"
GRQ_UPDATE_URL_BULK = "https://{{ GRQ_PVT_IP }}:{{ GRQ_PORT }}/api/v0.2/grq/dataset/index"

GRQ_ES_ENGINE = "{{ GRQ_ES_ENGINE or 'elasticsearch' }}"
GRQ_AWS_ES = {{ GRQ_AWS_ES or False }}
{%- if GRQ_ES_PVT_IP is iterable and GRQ_ES_PVT_IP is not string %}
GRQ_ES_URL = [
    {%- for url in GRQ_ES_PVT_IP %}
        {%- if url.startswith('https://') %}
    "{{ url }}",
        {%- else %}
    "{{ 'https://'~url if GRQ_AWS_ES == true or 'es.amazonaws.com' in url else 'https://'~url~':9200' }}",
        {%- endif %}
    {%- endfor %}
]
{%- else %}
    {%- if GRQ_ES_PVT_IP.startswith('https://') %}
GRQ_ES_URL = "{{ GRQ_ES_PVT_IP }}"
    {%- else %}
GRQ_ES_URL = "{{ 'https://'~GRQ_ES_PVT_IP if GRQ_AWS_ES == true or 'es.amazonaws.com' in GRQ_ES_PVT_IP else 'https://'~GRQ_ES_PVT_IP~':9200' }}"
    {%- endif %}
{%- endif %}

CONTAINER_ENGINE = "{{ CONTAINER_ENGINE or 'docker' }}"

PODMAN_CFG = {
  "set_uid_gid": False,
  "set_passwd_entry": True,
  "cmd_base": {
    # Commenting the userns setting out, but leaving it in here in case it needs to be set
    # "userns": "keep-id",
    "security-opt": "label=disable"
  },
  "environment": [
    "HOST_VERDI_HOME",
    "HOST_USER",
    "HOST_UID",
    "HYSDS_ROOT_WORK_DIR"
  ]
}

DATASET_PROCESSED_QUEUE = "dataset_processed"
USER_RULES_DATASET_QUEUE = "user_rules_dataset"
ON_DEMAND_DATASET_QUEUE = "on_demand_dataset"
USER_RULES_DATASET_INDEX = "user_rules-grq"
DATASET_ALIAS = "grq"

HYSDS_IOS_MOZART = "hysds_ios-mozart"
HYSDS_IOS_GRQ = "hysds_ios-grq"

USER_RULES_TRIGGER_QUEUE = "user_rules_trigger"

PROCESS_EVENTS_TASKS_QUEUE = "process_events_tasks"

METRICS_ES_ENGINE = "{{ METRICS_ES_ENGINE or 'elasticsearch' }}"
METRICS_AWS_ES = {{ METRICS_AWS_ES or False }}
{%- if METRICS_ES_PVT_IP is iterable and METRICS_ES_PVT_IP is not string %}
METRICS_ES_URL = [
    {%- for url in METRICS_ES_PVT_IP %}
        {%- if url.startswith('https://') %}
    "{{ url }}",
        {%- else %}
    "{{ 'https://'~url if METRICS_AWS_ES == true or 'es.amazonaws.com' in url else 'https://'~url~':9200' }}",
        {%- endif %}
    {%- endfor %}
]
{%- else %}
    {%- if METRICS_ES_PVT_IP.startswith('https://') %}
METRICS_ES_URL = "{{ METRICS_ES_PVT_IP }}"
    {%- else %}
METRICS_ES_URL = "{{ 'https://'~METRICS_ES_PVT_IP if METRICS_AWS_ES == true or 'es.amazonaws.com' in METRICS_ES_PVT_IP else 'https://'~METRICS_ES_PVT_IP~':9200' }}"
    {%- endif %}
{%- endif %}

REDIS_JOB_STATUS_URL = "rediss://:{{ MOZART_REDIS_PASSWORD }}@{{ MOZART_REDIS_PVT_IP }}/?ssl_cert_reqs=none"
REDIS_JOB_STATUS_KEY = "logstash"
REDIS_JOB_INFO_URL = "rediss://:{{ METRICS_REDIS_PASSWORD }}@{{ METRICS_REDIS_PVT_IP }}/?ssl_cert_reqs=none"
REDIS_JOB_INFO_KEY = "logstash"
REDIS_INSTANCE_METRICS_URL = "rediss://:{{ METRICS_REDIS_PASSWORD }}@{{ METRICS_REDIS_PVT_IP }}/?ssl_cert_reqs=none"
REDIS_INSTANCE_METRICS_KEY = "logstash"
REDIS_UNIX_DOMAIN_SOCKET = "unix://:{{ MOZART_REDIS_PASSWORD }}@/tmp/redis.sock"

WORKER_CONTIGUOUS_FAILURE_THRESHOLD = 10
WORKER_CONTIGUOUS_FAILURE_TIME = 5.

ROOT_WORK_DIR = "/data/work"
WEBDAV_URL = None
WEBDAV_PORT = 8085

WORKER_MOUNT_BLACKLIST = [
    "/dev",
    "/etc",
    "/lib",
    "/proc",
    "/usr",
    "/var",
]

CONTAINER_REGISTRY = "{{ CONTAINER_REGISTRY }}"

AWS_REGION = "{{ AWS_REGION }}"

ES_CLUSTER_MODE = {{ ES_CLUSTER_MODE or False }}

TRIAGE_PARTITION_FORMAT = {{ TRIAGE_PARTITION_FORMAT or None }}

VERDI_HOME = "{{ VERDI_HOME or '/root' }}"

VERDI_SHELL = "{{ VERDI_SHELL or '/bin/bash' }}"

CACHE_READ_ONLY = {{ CACHE_READ_ONLY | default(true, boolean=False) }}

EVICT_CACHE = {{ EVICT_CACHE | default(true, boolean=False) }}
